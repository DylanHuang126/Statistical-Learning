{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 b05705017 黃亮穎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Classification via Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "with open('phone_train.pickle', 'rb') as fh1:\n",
    "    traindata = pickle.load(fh1)\n",
    "\n",
    "with open('phone_test1.pickle', 'rb') as fh2:\n",
    "    testdata = pickle.load(fh2)\n",
    "    \n",
    "x_train = np.array(traindata)[:, :3].astype('float')\n",
    "y_train = np.array(traindata)[:, 3]\n",
    "x_test = np.array(testdata)[:, :3].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-1 create mypgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mypgc():\n",
    "    def __init__(self):\n",
    "        self.typ = np.array([\"Phoneonback\", \"Phoneonfront\", \"Phoneonleft\", \"Phoneonright\", \"Phoneontop\", \"Phoneonbottom\"])\n",
    "        \n",
    "    def fit(self, x_trian, y_train):\n",
    "        \n",
    "        def mu(typ):\n",
    "            mu = np.mean(x_train[y_train == typ], axis = 0)\n",
    "            return mu\n",
    "        \n",
    "        def cov(typ):\n",
    "            return np.cov(x_train[y_train == typ].T)\n",
    "        \n",
    "        mean = [[]] * 6\n",
    "        prior = [0] * 6\n",
    "        covar = np.zeros((3, 3))\n",
    "        r = len(y_train)\n",
    "        \n",
    "        for i, j in enumerate(self.typ):\n",
    "            mean[i] = mu(j)\n",
    "            prior[i] = np.sum(y_train == j) / r\n",
    "            covar += np.sum(y_train == j) / r * cov(j)\n",
    "        \n",
    "        self.mu = mean\n",
    "        self.cov = covar\n",
    "        self.prior = prior\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        def gaussian(x, mu, cov):\n",
    "            coef = 1 / ((np.sqrt(2 * np.pi) ** len(x)) * (np.sqrt(np.linalg.det(cov))))\n",
    "            index = (-1/2) * np.dot((x - mu).T, np.linalg.inv(cov))\n",
    "            index = np.dot(index, (x - mu))\n",
    "            prob = coef * np.exp(index)\n",
    "            return prob\n",
    "    \n",
    "        def position(x):\n",
    "            nume = np.zeros(6)\n",
    "            deno = 0\n",
    "            for i in range(len(self.typ)):\n",
    "                p = self.prior[i] * gaussian(x, self.mu[i], self.cov)\n",
    "                nume[i] = p\n",
    "                deno += p\n",
    "            prob = nume / deno\n",
    "            idx = np.argsort(prob)\n",
    "            return self.typ[idx[-1]]\n",
    "        \n",
    "        y_pred = np.array([position(i) for i in x_test])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-2 train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneonback :\n",
      "\n",
      " mu :\n",
      " [ 0.20693328 -0.02615235  9.7963762 ]\n",
      "\n",
      " cov :\n",
      " [[ 0.00299006 -0.00195813  0.00284766]\n",
      " [-0.00195813  0.00229887 -0.0024254 ]\n",
      " [ 0.00284766 -0.0024254   0.0048876 ]]\n",
      "\n",
      " prec :\n",
      " [[ 943.63669582  469.54782044 -316.78479596]\n",
      " [ 469.54782044 1146.63145078  295.42598486]\n",
      " [-316.78479596  295.42598486  535.76812508]]\n",
      "\n",
      " detcov :\n",
      " 5.673178805678628e-09\n",
      "\n",
      " n :\n",
      " 28566\n",
      "\n",
      " prior :\n",
      " 0.17095459523510295\n",
      "\n",
      "Phoneonfront :\n",
      "\n",
      " mu :\n",
      " [ 0.11270401  0.14265129 -9.73579633]\n",
      "\n",
      " cov :\n",
      " [[ 0.00173617 -0.00562249  0.00071319]\n",
      " [-0.00562249  0.03069977 -0.00386164]\n",
      " [ 0.00071319 -0.00386164  0.00185582]]\n",
      "\n",
      " prec :\n",
      " [[1415.5956848   258.4845593    -6.15206605]\n",
      " [ 258.4845593    91.32078358   90.68682325]\n",
      " [  -6.15206605   90.68682325  729.91124637]]\n",
      "\n",
      " detcov :\n",
      " 2.971267016655918e-08\n",
      "\n",
      " n :\n",
      " 29079\n",
      "\n",
      " prior :\n",
      " 0.1740246683064328\n",
      "\n",
      "Phoneonleft :\n",
      "\n",
      " mu :\n",
      " [ 9.92639446  0.09275717 -0.01933473]\n",
      "\n",
      " cov :\n",
      " [[ 0.00192839 -0.00619274  0.00063551]\n",
      " [-0.00619274  0.03200844 -0.00317611]\n",
      " [ 0.00063551 -0.00317611  0.00171996]]\n",
      "\n",
      " prec :\n",
      " [[1369.95113577  263.0134811   -20.49603676]\n",
      " [ 263.0134811    88.74589895   66.6992188 ]\n",
      " [ -20.49603676   66.6992188   712.14869845]]\n",
      "\n",
      " detcov :\n",
      " 3.282281658720177e-08\n",
      "\n",
      " n :\n",
      " 29522\n",
      "\n",
      " prior :\n",
      " 0.17667582302494958\n",
      "\n",
      "Phoneonright :\n",
      "\n",
      " mu :\n",
      " [-9.64916017e+00  7.86873275e-02 -7.71762134e-03]\n",
      "\n",
      " cov :\n",
      " [[ 0.00076675 -0.00067075  0.00068673]\n",
      " [-0.00067075  0.00682422 -0.00627087]\n",
      " [ 0.00068673 -0.00627087  0.00773266]]\n",
      "\n",
      " prec :\n",
      " [[1432.0246564    93.75083518  -51.14931824]\n",
      " [  93.75083518  581.24293978  463.03773646]\n",
      " [ -51.14931824  463.03773646  509.36831176]]\n",
      "\n",
      " detcov :\n",
      " 9.389257143958892e-09\n",
      "\n",
      " n :\n",
      " 25687\n",
      "\n",
      " prior :\n",
      " 0.1537250818386925\n",
      "\n",
      "Phoneontop :\n",
      "\n",
      " mu :\n",
      " [ 8.13769555e-04 -9.69990841e+00 -1.00215800e-01]\n",
      "\n",
      " cov :\n",
      " [[ 0.00184664  0.00529325 -0.00601384]\n",
      " [ 0.00529325  0.02519526 -0.02792123]\n",
      " [-0.00601384 -0.02792123  0.0331182 ]]\n",
      "\n",
      " prec :\n",
      " [[1380.20106989 -186.01874711   93.79832935]\n",
      " [-186.01874711  629.12383998  496.62195539]\n",
      " [  93.79832935  496.62195539  465.9185559 ]]\n",
      "\n",
      " detcov :\n",
      " 3.9723671816650785e-08\n",
      "\n",
      " n :\n",
      " 26401\n",
      "\n",
      " prior :\n",
      " 0.15799804903738546\n",
      "\n",
      "Phoneonbottom :\n",
      "\n",
      " mu :\n",
      " [0.19076794 9.78584734 0.1465572 ]\n",
      "\n",
      " cov :\n",
      " [[ 0.00273883 -0.0044379   0.00151984]\n",
      " [-0.0044379   0.01026786 -0.00328148]\n",
      " [ 0.00151984 -0.00328148  0.00247968]]\n",
      "\n",
      " prec :\n",
      " [[1229.24902343  503.42022589  -87.22678994]\n",
      " [ 503.42022589  374.93550309  187.61601574]\n",
      " [ -87.22678994  187.61601574  705.02302834]]\n",
      "\n",
      " detcov :\n",
      " 1.1952712798255282e-08\n",
      "\n",
      " n :\n",
      " 27842\n",
      "\n",
      " prior :\n",
      " 0.1666217825574367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pgc1 = mypgc()\n",
    "pgc1.fit(x_train, y_train)\n",
    "\n",
    "# calculate and show model parameters\n",
    "def mu(typ):\n",
    "    mu = np.mean(x_train[y_train == typ], axis = 0)\n",
    "    return mu\n",
    "\n",
    "def cov(typ):\n",
    "    return np.cov(x_train[y_train == typ].T)\n",
    "\n",
    "def prec(cov):\n",
    "    return np.linalg.inv(cov)\n",
    "\n",
    "def detcov(cov):\n",
    "    return np.linalg.det(cov)\n",
    "\n",
    "typp = [\"Phoneonback\", \"Phoneonfront\", \"Phoneonleft\", \"Phoneonright\", \"Phoneontop\", \"Phoneonbottom\"]\n",
    "\n",
    "model = {}\n",
    "for i in typp:\n",
    "     model[i] = {\"mu\" : mu(i), \"cov\" : cov(i), \"prec\" : prec(cov(i)), \"detcov\" : detcov(cov(i)), \"n\" : np.sum(y_train == i) , \"prior\" : np.sum(y_train == i) / len(y_train)}\n",
    "        \n",
    "for key, value in model.items():\n",
    "    print(key, \":\")\n",
    "    for key2, value2 in value.items():\n",
    "        print(\"\\n\", key2, \":\\n\", value2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-3 predict test data and show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 20 predictions and actual positions pair :\n",
      "|  prediction        |  actual              |\n",
      "[['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneontop' 'Phoneontop']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonleft' 'Phoneonleft']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneontop' 'Phoneontop']\n",
      " ['Phoneonleft' 'Phoneonleft']]\n",
      "\n",
      "numbers of correct predictions : 83511\n",
      "\n",
      "accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "ypred = pgc1.predict(x_test)\n",
    "\n",
    "res = np.array(list(it.zip_longest(ypred[:20], np.array(testdata['label'][:20]))))\n",
    "\n",
    "print(\"first 20 predictions and actual positions pair :\")\n",
    "print(\"|  prediction        |  actual              |\")\n",
    "print(res)\n",
    "\n",
    "correct = [ypred[i] == testdata['label'][i] for i in range(len(ypred))]\n",
    "accuracy = float(sum(correct)) / len(ypred)\n",
    "print()\n",
    "print(\"numbers of correct predictions :\", sum(correct))\n",
    "print()\n",
    "print(\"accuracy :\", \"{:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"adult.data.txt\", 'r')\n",
    "n = np.array(data.read().splitlines())\n",
    "\n",
    "test = open(\"adult.test.txt\", 'r')\n",
    "t = np.array(test.read().splitlines())\n",
    "\n",
    "dummy = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "conti = [0, 2, 4, 10, 11, 12]\n",
    "\n",
    "dfx = [[j.strip() for j in i.split(',')] for i in n]\n",
    "dfx = pd.DataFrame(dfx)\n",
    "\n",
    "for i in dfx.columns:\n",
    "    idx = dfx[dfx[i] == '?'].index\n",
    "    dfx.drop(idx, inplace = True)\n",
    "dfx = dfx.reset_index(drop = True)\n",
    "\n",
    "for i in dummy:\n",
    "    num = dfx[i].value_counts()\n",
    "    mask = dfx[i].isin(num[num > 10].index)\n",
    "    dfx = dfx[mask]\n",
    "    dfx.reset_index(drop = True)\n",
    "\n",
    "y_train = np.array(dfx[14])\n",
    "dfx = dfx.drop(columns = [14])\n",
    "y_train[y_train == \"<=50K\"] = 0\n",
    "y_train[y_train == \">50K\"] = 1\n",
    "y_train = y_train.astype('float')\n",
    "\n",
    "categories = {}\n",
    "for i in dummy:\n",
    "    dfx[i] = dfx[i].astype('category')\n",
    "    categories[i] = dfx[i].cat.categories\n",
    "\n",
    "x_train = pd.get_dummies(dfx, columns = dummy)\n",
    "x_train = np.array(x_train).astype('float')\n",
    "dfxt = [[j.strip() for j in i.split(',')] for i in t]\n",
    "dfxt = pd.DataFrame(dfxt)\n",
    "\n",
    "\n",
    "for i in dfxt.columns:\n",
    "    idx = dfxt[dfxt[i] == '?'].index\n",
    "    dfxt.drop(idx, inplace = True)\n",
    "dfxt = dfxt.reset_index(drop = True)\n",
    "\n",
    "y_test = np.array(dfxt[14])\n",
    "dfxt = dfxt.drop(columns = [14])\n",
    "y_test[y_test == \"<=50K.\"] = 0\n",
    "y_test[y_test == \">50K.\"] = 1\n",
    "y_test = y_test.astype('float')\n",
    "\n",
    "for i in dummy:\n",
    "    dfxt[i] = dfxt[i].astype('category')\n",
    "    dfxt[i].cat.set_categories(categories[i], inplace = True)\n",
    "\n",
    "x_test = pd.get_dummies(dfxt, columns = dummy)\n",
    "x_test = np.array(x_test).astype('float')\n",
    "\n",
    "mean = np.mean(x_train[:, :6], axis = 0)\n",
    "std = np.std(x_train[:, :6], axis = 0)\n",
    "x_train[:, :6] = (x_train[:, :6] - mean) / std\n",
    "x_test[:, :6] = (x_test[:, :6] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary statistics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train : (30152, 102)\n",
      "shape of x_test :  (15060, 102)\n",
      "shape of y_train : (30152,)\n",
      "shape of y_test : (15060,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x_train :\", x_train.shape)\n",
    "print(\"shape of x_test : \", x_test.shape)\n",
    "print(\"shape of y_train :\", y_train.shape)\n",
    "print(\"shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.187694e-16</td>\n",
       "      <td>-2.710016e-17</td>\n",
       "      <td>-2.801921e-16</td>\n",
       "      <td>-2.226927e-17</td>\n",
       "      <td>-6.244820e-17</td>\n",
       "      <td>1.861663e-16</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.739089</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.911880</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>0.173257</td>\n",
       "      <td>0.252696</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.060017</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.024426</td>\n",
       "      <td>0.283474</td>\n",
       "      <td>0.046023</td>\n",
       "      <td>0.023030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632305e+00</td>\n",
       "      <td>-1.666013e+00</td>\n",
       "      <td>-3.576761e+00</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-3.333285e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.948575e-01</td>\n",
       "      <td>-6.830421e-01</td>\n",
       "      <td>-4.397050e-01</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-7.774463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.096728e-01</td>\n",
       "      <td>-1.075818e-01</td>\n",
       "      <td>-4.757293e-02</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-7.774463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.516436e-01</td>\n",
       "      <td>4.527373e-01</td>\n",
       "      <td>1.128823e+00</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>3.396324e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.925304e+00</td>\n",
       "      <td>1.225606e+01</td>\n",
       "      <td>2.305219e+00</td>\n",
       "      <td>1.335236e+01</td>\n",
       "      <td>1.056266e+01</td>\n",
       "      <td>4.847304e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  3.015200e+04  3.015200e+04  3.015200e+04  3.015200e+04  3.015200e+04   \n",
       "mean  -1.187694e-16 -2.710016e-17 -2.801921e-16 -2.226927e-17 -6.244820e-17   \n",
       "std    1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00   \n",
       "min   -1.632305e+00 -1.666013e+00 -3.576761e+00 -1.474696e-01 -2.184590e-01   \n",
       "25%   -7.948575e-01 -6.830421e-01 -4.397050e-01 -1.474696e-01 -2.184590e-01   \n",
       "50%   -1.096728e-01 -1.075818e-01 -4.757293e-02 -1.474696e-01 -2.184590e-01   \n",
       "75%    6.516436e-01  4.527373e-01  1.128823e+00 -1.474696e-01 -2.184590e-01   \n",
       "max    3.925304e+00  1.225606e+01  2.305219e+00  1.335236e+01  1.056266e+01   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  3.015200e+04  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean   1.861663e-16      0.030976      0.068553      0.739089      0.035620   \n",
       "std    1.000017e+00      0.173257      0.252696      0.439139      0.185343   \n",
       "min   -3.333285e+00      0.000000      0.000000      0.000000      0.000000   \n",
       "25%   -7.774463e-02      0.000000      0.000000      0.000000      0.000000   \n",
       "50%   -7.774463e-02      0.000000      0.000000      1.000000      0.000000   \n",
       "75%    3.396324e-01      0.000000      0.000000      1.000000      0.000000   \n",
       "max    4.847304e+00      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           92            93            94            95   \\\n",
       "count  ...  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean   ...      0.001128      0.003615      0.000365      0.002355   \n",
       "std    ...      0.033562      0.060017      0.019097      0.048469   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                96            97            98            99            100  \\\n",
       "count  30152.000000  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean       0.001393      0.000564      0.000597      0.911880      0.002123   \n",
       "std        0.037297      0.023738      0.024426      0.283474      0.046023   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                101  \n",
       "count  30152.000000  \n",
       "mean       0.000531  \n",
       "std        0.023030  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x_train)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.024953</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.018693</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>1.003359</td>\n",
       "      <td>1.039927</td>\n",
       "      <td>1.005553</td>\n",
       "      <td>1.006950</td>\n",
       "      <td>0.172628</td>\n",
       "      <td>0.252768</td>\n",
       "      <td>0.443034</td>\n",
       "      <td>0.191158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632305</td>\n",
       "      <td>-1.668635</td>\n",
       "      <td>-3.576761</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-3.333285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.794857</td>\n",
       "      <td>-0.692221</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-0.077745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.109673</td>\n",
       "      <td>-0.112030</td>\n",
       "      <td>-0.047573</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-0.077745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.727775</td>\n",
       "      <td>0.461854</td>\n",
       "      <td>1.128823</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>0.339632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.925304</td>\n",
       "      <td>12.309959</td>\n",
       "      <td>2.305219</td>\n",
       "      <td>13.352363</td>\n",
       "      <td>9.112309</td>\n",
       "      <td>4.847304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.024953     -0.001658     -0.003360      0.003771      0.001920   \n",
       "std        1.018693      0.999622      1.003359      1.039927      1.005553   \n",
       "min       -1.632305     -1.668635     -3.576761     -0.147470     -0.218459   \n",
       "25%       -0.794857     -0.692221     -0.439705     -0.147470     -0.218459   \n",
       "50%       -0.109673     -0.112030     -0.047573     -0.147470     -0.218459   \n",
       "75%        0.727775      0.461854      1.128823     -0.147470     -0.218459   \n",
       "max        3.925304     12.309959      2.305219     13.352363      9.112309   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.001690      0.030744      0.068592      0.731806      0.037981   \n",
       "std        1.006950      0.172628      0.252768      0.443034      0.191158   \n",
       "min       -3.333285      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       -0.077745      0.000000      0.000000      0.000000      0.000000   \n",
       "50%       -0.077745      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.339632      0.000000      0.000000      1.000000      0.000000   \n",
       "max        4.847304      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           92            93            94            95   \\\n",
       "count  ...  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean   ...      0.001859      0.004382      0.000598      0.001992   \n",
       "std    ...      0.043080      0.066057      0.024440      0.044589   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                96            97            98            99            100  \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.000863      0.000797      0.000531      0.915538      0.001262   \n",
       "std        0.029369      0.028218      0.023043      0.278089      0.035498   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                101  \n",
       "count  15060.000000  \n",
       "mean       0.000465  \n",
       "std        0.021555  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(x_test)\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2:\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept    \n",
    "        \n",
    "    def fit(self, x_train, y_train, verbose = False):\n",
    "        \n",
    "        if self.add_intercept:\n",
    "            self.x_train = np.c_[x_train, np.ones(x_train.shape[0])]\n",
    "        else:\n",
    "            self.x_train = x_train\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        \n",
    "        w = np.linalg.inv(np.dot(self.x_train.T, self.x_train) + np.mean(self.reg_vec) * np.identity(self.reg_vec.shape[0]))\n",
    "        w = np.dot(w, self.x_train.T)\n",
    "        w = np.dot(w, self.y_train)\n",
    "        self.w = w\n",
    "        e = self.reg_error(self.x_train, self.y_train, self.w, self.reg_vec)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            z = np.dot(self.x_train, self.w)\n",
    "            pred = self.sigmoid(z)\n",
    "            error = pred - self.y_train\n",
    "            grad = (self.reg_vec * self.w) + np.dot(self.x_train.T, error)\n",
    "            R = pred * (1 - pred)\n",
    "            hess = self.x_train.T * R\n",
    "            hess = np.dot(hess, self.x_train) + np.identity(self.reg_vec.shape[0]) * self.reg_vec\n",
    "            if i == 0 and verbose:\n",
    "                print(\"gradient :\", grad)\n",
    "                print(\"hessian :\", hess)\n",
    "            self.w = self.w - np.dot(np.linalg.pinv(hess), grad)\n",
    "            \n",
    "            next_error = self.reg_error(self.x_train, self.y_train, self.w, self.reg_vec)\n",
    "            if abs(e - next_error) < self.tol:\n",
    "                break\n",
    "            e = next_error\n",
    "            \n",
    "    def predict(self, x_test):\n",
    "        if self.add_intercept:\n",
    "            x_test = np.c_[x_test, np.ones(x_test.shape[0])]\n",
    "        z = np.dot(x_test, self.w)\n",
    "        res = np.array([self.sigmoid(i) for i in z])\n",
    "        res[res >= 0.5] = 1\n",
    "        res[res < 0.5] = 0\n",
    "        return res\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def reg_error(self, x_train, y_train, w, reg_vec):\n",
    "        z = np.dot(x_train, w) \n",
    "        reg_term = (1/2) * np.dot(reg_vec * w.T, w)\n",
    "        return -1 * np.sum((y_train * np.log(self.sigmoid(z) + 1e-5)) + ((1 - y_train) * np.log(1 - self.sigmoid(z) + 1e-5))) + reg_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2 Derive the gradient and hession matrix for the new E(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient : [-2.39097995e+03  8.86325719e+01 -3.32606519e+03 -2.25982859e+03\n",
      " -1.49120297e+03 -2.27153516e+03  1.91715719e+02  5.73307313e+02\n",
      "  7.45742056e+03  8.02662888e+01  7.09574275e+02  3.79304697e+02\n",
      "  6.91263270e+00  3.65511509e+02  4.79521522e+02  1.66132495e+02\n",
      "  7.10235693e+01  1.34989900e+02  2.52152806e+02  2.08660882e+02\n",
      "  3.10885150e+02  3.94138412e+02  9.12643019e+02 -2.63477247e+01\n",
      "  3.69979223e+03  1.16733475e+02  2.25693199e+01 -3.98688825e+01\n",
      "  2.32996381e+03  1.76670691e+03  3.06424960e+00  2.18847874e+03\n",
      "  1.61627191e+02  4.50554470e+03  4.19771023e+02  3.53308682e+02\n",
      "  1.48508201e+03  1.33128508e+03  5.27277285e+02  4.07853917e+02\n",
      "  6.12445983e+02  7.98083241e+02  1.50637200e+03  7.07478380e+01\n",
      "  6.44603724e+02  1.63657457e+02  1.05898674e+03  2.46244066e+02\n",
      "  5.45862140e+02  1.93281196e+03  3.24131972e+03  4.16617237e+02\n",
      "  2.18423393e+03  1.44565502e+03  1.77863620e+02  1.16865205e+02\n",
      "  2.59809092e+02  1.13181834e+03  9.95511842e+01  7.79045766e+03\n",
      "  4.05062335e+03  5.34787814e+03  3.84104720e+00  2.62815469e+01\n",
      "  1.88210609e+01  2.64243891e+01  2.71323458e+01  3.19707983e+01\n",
      "  1.04857823e+01  4.32012902e+01  2.03507833e+01  4.47934874e+00\n",
      "  3.07544422e+01  8.38725735e+00  2.92743906e+01  1.79833435e+01\n",
      "  5.24124900e+00  4.95342869e+00  4.23697154e+00  1.95750513e+01\n",
      "  7.38440049e+00  8.28578802e+00  1.59469657e+01  3.24669684e+01\n",
      "  1.20840088e+01  6.94758781e+00  2.80091099e+02  1.49634546e+01\n",
      "  6.90869879e+00  1.34612990e+01  4.86392465e+01  1.96984953e+01\n",
      "  1.39802542e+01  4.54444683e+01  3.95319017e+00  2.48427884e+01\n",
      "  6.52768915e+00  6.19773388e+00  7.47225986e+00  8.45810407e+03\n",
      "  2.81794564e+01  3.52703637e+00  9.39850149e+03]\n",
      "hessian : [[ 7.31602262e+03 -5.64070289e+02  2.47178715e+02 ... -6.21685753e+00\n",
      "   9.03445767e-02 -9.97615482e+01]\n",
      " [-5.64070289e+02  7.31679865e+03 -3.36818175e+02 ... -3.66620704e+00\n",
      "   9.08744089e-01  3.59043693e+00]\n",
      " [ 2.47178715e+02 -3.36818175e+02  7.19667380e+03 ... -3.91324620e+00\n",
      "  -3.68190685e-01 -1.65435707e+02]\n",
      " ...\n",
      " [-6.21685753e+00 -3.66620704e+00 -3.91324620e+00 ...  1.67849594e+01\n",
      "   0.00000000e+00  1.57849594e+01]\n",
      " [ 9.03445767e-02  9.08744089e-01 -3.68190685e-01 ...  0.00000000e+00\n",
      "   4.82412100e+00  3.82412100e+00]\n",
      " [-9.97615482e+01  3.59043693e+00 -1.65435707e+02 ...  1.57849594e+01\n",
      "   3.82412100e+00  7.30889100e+03]]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.array([1] * (x_train.shape[1] + 1))\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w :\n",
      "[ 3.33300239e-01  7.91950118e-02  7.50781031e-01  2.33387540e+00\n",
      "  2.58016680e-01  3.52920655e-01  5.03917484e-01 -1.87836061e-01\n",
      "  1.95888083e-03  1.77435295e-01 -4.85830477e-01 -3.09824864e-01\n",
      " -1.02513995e+00 -7.37006767e-04 -1.96244035e-01 -1.34587849e-01\n",
      "  6.26654377e-01  4.48135863e-01  2.46645745e-02  4.68906082e-02\n",
      " -4.90177174e-01 -2.02164859e-01 -1.62129305e-01 -1.61301013e-02\n",
      " -1.10533240e-01 -9.86066332e-02 -1.17390699e+00  1.82003137e-01\n",
      " -6.84510520e-02 -7.20124646e-01  1.45016439e+00  1.16040810e+00\n",
      " -6.78265843e-01 -1.20885947e+00 -7.96290058e-01 -5.32352175e-01\n",
      "  1.83346713e-02  8.34528999e-02  8.19526649e-01 -9.60845325e-01\n",
      " -6.63925233e-01 -2.43581800e-01 -7.94506650e-01 -1.63580895e+00\n",
      "  5.32751247e-01  6.06061717e-01  3.10770631e-01  6.74052130e-01\n",
      " -7.16016722e-02 -2.58776529e-01 -2.92864853e-02 -7.93917742e-01\n",
      " -1.16056471e+00 -1.53654181e-01  1.07087996e+00 -6.25219676e-01\n",
      "  1.19552636e-01 -2.28357231e-01 -5.14768775e-01 -7.65266427e-02\n",
      " -1.08972678e+00 -2.35592907e-01  9.75193051e-01  4.61450955e-01\n",
      " -4.94708603e-01 -1.27235110e+00  4.86801499e-01 -8.99573412e-01\n",
      " -6.00896915e-02 -3.51001958e-01  4.33038017e-01  5.94213718e-01\n",
      "  5.82335078e-01 -6.20479443e-01 -6.01785737e-02  9.29898148e-02\n",
      " -1.51823749e-01 -4.89194672e-03  3.46693430e-02 -2.88548001e-01\n",
      "  1.56332237e-01  4.95438419e-01  8.91045641e-01  1.49152095e-01\n",
      "  3.43031792e-01 -3.13162011e-01 -3.56026893e-01 -3.63380673e-01\n",
      " -6.67136293e-01 -4.08575889e-01  4.47570528e-01  1.38122777e-01\n",
      "  1.40892037e-01 -1.15949467e-01 -5.59568687e-02 -9.33796601e-01\n",
      " -2.84950674e-02 -2.98667727e-01 -1.50184146e-01  3.52712929e-01\n",
      " -7.85836640e-01  5.80505134e-01 -1.32531969e+00]\n",
      "\n",
      "accuracy : 84.7809%\n"
     ]
    }
   ],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.4%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.array([1] * (x_train.shape[1]) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w :\n",
      "[ 0.33364317  0.07921947  0.73771785  2.33349074  0.25802921  0.35304508\n",
      "  0.70874053  0.01734641  0.20829646  0.38214911 -0.28024988 -0.10512748\n",
      " -0.93115516  0.07202585 -0.11834194 -0.05311322  0.67152053  0.50324191\n",
      "  0.08716597  0.11338255 -0.38546955 -0.10254933 -0.05190874  0.10710446\n",
      " -0.02050343  0.01627788 -1.16578489  0.30036517  0.02658678 -0.52710016\n",
      "  1.61481294  1.36915804 -0.49315002 -1.01479456 -0.60643628 -0.34248996\n",
      "  0.12439724  0.18891847  0.92533953 -0.8562578  -0.55974627 -0.13823864\n",
      " -0.68865402 -1.57553304  0.63935265  0.71143584  0.416165    0.77915193\n",
      "  0.03366911 -0.04466318  0.20015783 -0.57913369 -0.93735843  0.07576444\n",
      "  1.28523303 -0.36713728  0.39299715  0.04223838 -0.26282764  0.1947294\n",
      " -0.42725385  0.42725385  1.00666429  0.50194614 -0.45741932 -1.24076572\n",
      "  0.52725371 -0.86931547 -0.02818841 -0.31476459  0.47306518  0.62939891\n",
      "  0.62362559 -0.58679235 -0.03048527  0.12377705 -0.14381483  0.02438259\n",
      "  0.06221836 -0.24850166  0.19431027  0.52579686  0.93116266  0.1865184\n",
      "  0.37948061 -0.28771528 -0.31207765 -0.33410385 -0.65131313 -0.38174468\n",
      "  0.48828828  0.17640105  0.17321021 -0.07397693 -0.03168121 -0.89825024\n",
      "  0.00673609 -0.27239488 -0.12449448  0.39668055 -0.75364105  0.61052419\n",
      " -3.13290402]\n",
      "\n",
      "accuracy : 84.7809%\n"
     ]
    }
   ],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.4%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.array([1] * 6 + [0.5] * (x_train.shape[1] - 6) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w :\n",
      "[ 0.33420362  0.07934715  0.78245531  2.33563809  0.25820902  0.35331032\n",
      "  0.76974011  0.07589062  0.26756247  0.4425935  -0.22119325 -0.04686142\n",
      " -1.28773203  0.18176537 -0.02660347  0.01937259  0.8977025   0.68435782\n",
      "  0.23217308  0.24428472 -0.38422598 -0.08085138 -0.06537975  0.04502774\n",
      "  0.03694934 -0.01388755 -2.09391972  0.25717122  0.06606347 -0.57253724\n",
      "  1.82595484  1.39795845 -0.54771851 -1.05883542 -0.65626908 -0.38855304\n",
      "  0.16435265  0.2285428   0.96654543 -0.82320513 -0.52463501 -0.09825492\n",
      " -0.65394918 -2.04836557  0.67978665  0.75553079  0.45687204  0.82328825\n",
      "  0.0734912  -0.08585855  0.23338451 -0.58848398 -0.9231019   0.11168247\n",
      "  1.25237746 -0.37878867  0.4116955   0.04056691 -0.26545931  0.19198557\n",
      " -0.42917962  0.42917962  1.18537608  0.55010209 -0.47590613 -1.45953272\n",
      "  0.58133206 -1.06413979 -0.01038468 -0.31799658  0.52415315  0.7297059\n",
      "  0.67380915 -0.63657862 -0.01087692  0.17268524 -0.23664217  0.03733919\n",
      "  0.10100075 -0.24715609  0.23741301  0.64150988  1.00483845  0.2316742\n",
      "  0.4223502  -0.35384864 -0.29280255 -0.38288917 -0.96325271 -0.45049215\n",
      "  0.51218033  0.21965656  0.22512441 -0.05074987 -0.01887939 -0.95959102\n",
      "  0.01649076 -0.32773494 -0.14044758  0.42792986 -0.84552461  0.75075505\n",
      " -3.28809175]\n",
      "\n",
      "accuracy : 84.7676%\n"
     ]
    }
   ],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.4%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1*, a2* : 12.915496650148826\n",
      "accuracy : 85.5438%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_tune, y_train_s, y_tune = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "max_acc = 0\n",
    "alpha = 0\n",
    "grids = np.logspace(-2, 2, 10)\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([i] * (x_train.shape[1]) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        alpha = i\n",
    "print(\"a1*, a2* :\", alpha)\n",
    "print(\"accuracy :\", \"{:.4%}\".format(max_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search new a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2* : 4.6415888336127775\n",
      "accuracy : 85.58%\n"
     ]
    }
   ],
   "source": [
    "alpha2 = 0\n",
    "max_acc2 = 0\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([alpha] * 6 + [i] * (x_train.shape[1] - 6) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc2:\n",
    "        max_acc2 = acc\n",
    "        alpha2 = i\n",
    "print(\"a2* :\", alpha2)\n",
    "print(\"accuracy :\", \"{:.2%}\".format(max_acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search new a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1* : 12.915496650148826\n",
      "accuracy : 85.5769%\n"
     ]
    }
   ],
   "source": [
    "alpha1 = 0\n",
    "max_acc1 = 0\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([i] * 6 + [alpha2] * (x_train.shape[1] - 6) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc1:\n",
    "        max_acc1 = acc\n",
    "        alpha1 = i\n",
    "print(\"a1* :\", alpha1)\n",
    "print(\"accuracy :\", \"{:.4%}\".format(max_acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 report a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best a1 : 12.915496650148826\n",
      "best a2 : 4.6415888336127775\n"
     ]
    }
   ],
   "source": [
    "print(\"best a1 :\", alpha1)\n",
    "print(\"best a2 :\", alpha2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 84.8074%\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.array([alpha1] * 6 + [alpha2] * (x_train.shape[1] - 6) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train, False)\n",
    "p = logic1.predict(x_test)\n",
    "acc = sum(p == y_test) / len(y_test)\n",
    "print(\"accuracy :\", \"{:.4%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== scikit learn logistic regression model result ======\n",
      "w :\n",
      "[[ 3.33032097e-01  7.79814273e-02  6.92675553e-01  2.16601256e+00\n",
      "   2.53795679e-01  3.48928264e-01  5.36557610e-01 -9.23816497e-02\n",
      "   7.60354219e-02  2.40070549e-01 -4.00265480e-01 -2.02553538e-01\n",
      "  -1.51723129e-01 -1.68347521e-02 -1.57164065e-01 -7.29630030e-02\n",
      "   1.49252378e-01  1.57764520e-01 -3.08548222e-02 -1.44652703e-02\n",
      "  -3.10075462e-01 -8.27678192e-02  4.75597725e-04  1.48484483e-01\n",
      "  -5.07572586e-02  7.22570423e-02 -1.16220104e-01  3.09621546e-01\n",
      "   1.99867719e-02 -2.86224348e-01  4.16550872e-01  1.25528953e+00\n",
      "  -1.84519022e-01 -7.70352401e-01 -3.06964196e-01 -1.18040652e-01\n",
      "   1.37662516e-02  7.34688638e-02  7.84722334e-01 -8.35258541e-01\n",
      "  -5.68510500e-01 -2.34601054e-01 -7.16818268e-01 -3.39148763e-01\n",
      "   5.07934386e-01  5.14180175e-01  2.86321788e-01  5.93590782e-01\n",
      "  -7.39076710e-02  1.41424449e-01  1.83145686e-02 -4.35890569e-01\n",
      "  -8.93595699e-01 -1.32109716e-01  1.30759675e+00 -2.34456344e-01\n",
      "   2.19144605e-01  2.33424328e-02 -1.89931788e-01  1.87640878e-01\n",
      "  -3.79075130e-01  3.84814913e-01  2.27578056e-01  1.98243246e-01\n",
      "  -1.85279692e-01 -3.32227245e-01  1.89537440e-01 -2.07900746e-01\n",
      "  -2.89464283e-02 -1.37499513e-01  1.74034837e-01  1.55609805e-01\n",
      "   2.82894642e-01 -1.87059200e-01 -2.70433001e-02  2.83496319e-03\n",
      "  -1.65249363e-02  9.08612879e-03 -5.37746024e-03 -1.26192056e-01\n",
      "   2.92811069e-02  9.16591329e-02  3.77263311e-01  2.16749339e-02\n",
      "   1.32998676e-01 -4.67793315e-02 -2.90803784e-01 -8.96070515e-02\n",
      "  -9.13800140e-02 -9.04615039e-02  3.06727661e-01  1.40605903e-02\n",
      "   2.02732921e-02 -8.18553918e-02 -1.71616538e-02 -3.35720339e-01\n",
      "   1.08477606e-02 -5.10332191e-02 -2.89274914e-02  2.50795532e-01\n",
      "  -2.14095704e-01  1.02214728e-01]]\n",
      "\n",
      "accuracy : 84.8074%\n",
      "\n",
      "====== my own logistic regression model result ======\n",
      "w :\n",
      "[ 0.33080467  0.07825843  0.65645406  2.17456732  0.25431472  0.349844\n",
      "  0.59733089 -0.07237493  0.11013046  0.2802571  -0.37291656 -0.19183719\n",
      " -0.35058977 -0.06337774 -0.20819861 -0.11061189  0.26619756  0.21136626\n",
      " -0.09730425 -0.05784526 -0.31686459 -0.07869758  0.03218142  0.24962699\n",
      " -0.06415555  0.12522336 -0.3116328   0.40866409  0.01542861 -0.37258543\n",
      "  0.86678898  1.29137328 -0.30396337 -0.86046927 -0.42855101 -0.19259319\n",
      "  0.04955603  0.11189927  0.83908894 -0.88238059 -0.60133112 -0.21105051\n",
      " -0.73661076 -0.70058908  0.5602917   0.60349334  0.33409629  0.67593043\n",
      " -0.04239393  0.07850615  0.09391723 -0.52278107 -0.95285807 -0.04502507\n",
      "  1.34824083 -0.30395194  0.30506567  0.04083571 -0.23909464  0.1971452\n",
      " -0.41093886  0.41093886  0.48995395  0.33400846 -0.31558225 -0.64722103\n",
      "  0.33860076 -0.42293419 -0.04028271 -0.22694785  0.30652986  0.32906457\n",
      "  0.44532367 -0.35056236 -0.04099742  0.02648294 -0.0409402   0.01120403\n",
      "  0.00530231 -0.1950141   0.08162451  0.22263848  0.63750588  0.06913341\n",
      "  0.23897043 -0.11649054 -0.33568633 -0.17838474 -0.21863653 -0.18805452\n",
      "  0.40882466  0.06630417  0.05792772 -0.10077803 -0.03115315 -0.59329362\n",
      "  0.00681518 -0.11795014 -0.06377672  0.31195211 -0.41692029  0.2534396\n",
      " -2.9100247 ]\n",
      "\n",
      "accuracy : 84.8074%\n",
      "\n",
      "accuracy difference between two models : 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "max_acc = 0\n",
    "best_c = 0\n",
    "for c in grids:\n",
    "    logic2 = LogisticRegression(solver = 'lbfgs', max_iter = 1000, tol = 1e-5, n_jobs = -1, C = c)\n",
    "    logic2.fit(x_train_s, y_train_s)\n",
    "    p = logic2.predict(x_tune)\n",
    "    accc = sum(p == y_tune) / len(y_tune)\n",
    "    if accc > max_acc:\n",
    "        max_acc = accc\n",
    "        best_c = c\n",
    "        \n",
    "logic2 = LogisticRegression(solver = 'lbfgs', max_iter = 1000, tol = 1e-5, n_jobs = -1, C = best_c)\n",
    "logic2.fit(x_train, y_train)\n",
    "p = logic2.predict(x_test)\n",
    "acc2 = sum(p == y_test) / len(y_test)\n",
    "\n",
    "print(\"====== scikit learn logistic regression model result ======\")\n",
    "print(\"w :\")\n",
    "print(logic2.coef_)\n",
    "print(\"\\naccuracy :\", \"{:.4%}\".format(acc2))\n",
    "\n",
    "print(\"\\n====== my own logistic regression model result ======\")\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.4%}\".format(acc))\n",
    "\n",
    "print(\"\\naccuracy difference between two models :\", abs(acc - acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When random state is set to 42, two models have same prediction ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
