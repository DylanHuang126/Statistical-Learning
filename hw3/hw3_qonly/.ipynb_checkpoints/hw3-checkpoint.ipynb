{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 b05705017 黃亮穎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Classification via Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "with open('phone_train.pickle', 'rb') as fh1:\n",
    "    traindata = pickle.load(fh1)\n",
    "\n",
    "with open('phone_test1.pickle', 'rb') as fh2:\n",
    "    testdata = pickle.load(fh2)\n",
    "    \n",
    "x_train = np.array(traindata)[:, :3].astype('float')\n",
    "y_train = np.array(traindata)[:, 3]\n",
    "x_test = np.array(testdata)[:, :3].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-1 create mypgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mypgc():\n",
    "    def __init__(self):\n",
    "        self.typ = np.array([\"Phoneonback\", \"Phoneonfront\", \"Phoneonleft\", \"Phoneonright\", \"Phoneontop\", \"Phoneonbottom\"])\n",
    "        \n",
    "    def fit(self, x_trian, y_train):\n",
    "        \n",
    "        def mu(typ):\n",
    "            mu = np.mean(x_train[y_train == typ], axis = 0)\n",
    "            return mu\n",
    "        \n",
    "        def cov(typ):\n",
    "            return np.cov(x_train[y_train == typ].T)\n",
    "        \n",
    "        mean = [[]] * 6\n",
    "        prior = [0] * 6\n",
    "        covar = np.zeros((3, 3))\n",
    "        r = len(y_train)\n",
    "        \n",
    "        for i, j in enumerate(self.typ):\n",
    "            mean[i] = mu(j)\n",
    "            prior[i] = np.sum(y_train == j) / r\n",
    "            covar += np.sum(y_train == j) / r * cov(j)\n",
    "        \n",
    "        self.mu = mean\n",
    "        self.cov = covar\n",
    "        self.prior = prior\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        def gaussian(x, mu, cov):\n",
    "            coef = 1 / ((np.sqrt(2 * np.pi) ** len(x)) * (np.sqrt(np.linalg.det(cov))))\n",
    "            index = (-1/2) * np.dot((x - mu).T, np.linalg.inv(cov))\n",
    "            index = np.dot(index, (x - mu))\n",
    "            prob = coef * np.exp(index)\n",
    "            return prob\n",
    "    \n",
    "        def position(x):\n",
    "            nume = np.zeros(6)\n",
    "            deno = 0\n",
    "            for i in range(len(self.typ)):\n",
    "                p = self.prior[i] * gaussian(x, self.mu[i], self.cov)\n",
    "                nume[i] = p\n",
    "                deno += p\n",
    "            prob = nume / deno\n",
    "            idx = np.argsort(prob)\n",
    "            return self.typ[idx[-1]]\n",
    "        \n",
    "        y_pred = np.array([position(i) for i in x_test])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-2 train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneonback :\n",
      "\n",
      " mu :\n",
      " [ 0.20693328 -0.02615235  9.7963762 ]\n",
      "\n",
      " cov :\n",
      " [[ 0.00299006 -0.00195813  0.00284766]\n",
      " [-0.00195813  0.00229887 -0.0024254 ]\n",
      " [ 0.00284766 -0.0024254   0.0048876 ]]\n",
      "\n",
      " prec :\n",
      " [[ 943.63669582  469.54782044 -316.78479596]\n",
      " [ 469.54782044 1146.63145078  295.42598486]\n",
      " [-316.78479596  295.42598486  535.76812508]]\n",
      "\n",
      " detcov :\n",
      " 5.673178805678628e-09\n",
      "\n",
      " n :\n",
      " 28566\n",
      "\n",
      " prior :\n",
      " 0.17095459523510295\n",
      "\n",
      "Phoneonfront :\n",
      "\n",
      " mu :\n",
      " [ 0.11270401  0.14265129 -9.73579633]\n",
      "\n",
      " cov :\n",
      " [[ 0.00173617 -0.00562249  0.00071319]\n",
      " [-0.00562249  0.03069977 -0.00386164]\n",
      " [ 0.00071319 -0.00386164  0.00185582]]\n",
      "\n",
      " prec :\n",
      " [[1415.5956848   258.4845593    -6.15206605]\n",
      " [ 258.4845593    91.32078358   90.68682325]\n",
      " [  -6.15206605   90.68682325  729.91124637]]\n",
      "\n",
      " detcov :\n",
      " 2.971267016655918e-08\n",
      "\n",
      " n :\n",
      " 29079\n",
      "\n",
      " prior :\n",
      " 0.1740246683064328\n",
      "\n",
      "Phoneonleft :\n",
      "\n",
      " mu :\n",
      " [ 9.92639446  0.09275717 -0.01933473]\n",
      "\n",
      " cov :\n",
      " [[ 0.00192839 -0.00619274  0.00063551]\n",
      " [-0.00619274  0.03200844 -0.00317611]\n",
      " [ 0.00063551 -0.00317611  0.00171996]]\n",
      "\n",
      " prec :\n",
      " [[1369.95113577  263.0134811   -20.49603676]\n",
      " [ 263.0134811    88.74589895   66.6992188 ]\n",
      " [ -20.49603676   66.6992188   712.14869845]]\n",
      "\n",
      " detcov :\n",
      " 3.282281658720177e-08\n",
      "\n",
      " n :\n",
      " 29522\n",
      "\n",
      " prior :\n",
      " 0.17667582302494958\n",
      "\n",
      "Phoneonright :\n",
      "\n",
      " mu :\n",
      " [-9.64916017e+00  7.86873275e-02 -7.71762134e-03]\n",
      "\n",
      " cov :\n",
      " [[ 0.00076675 -0.00067075  0.00068673]\n",
      " [-0.00067075  0.00682422 -0.00627087]\n",
      " [ 0.00068673 -0.00627087  0.00773266]]\n",
      "\n",
      " prec :\n",
      " [[1432.0246564    93.75083518  -51.14931824]\n",
      " [  93.75083518  581.24293978  463.03773646]\n",
      " [ -51.14931824  463.03773646  509.36831176]]\n",
      "\n",
      " detcov :\n",
      " 9.389257143958892e-09\n",
      "\n",
      " n :\n",
      " 25687\n",
      "\n",
      " prior :\n",
      " 0.1537250818386925\n",
      "\n",
      "Phoneontop :\n",
      "\n",
      " mu :\n",
      " [ 8.13769555e-04 -9.69990841e+00 -1.00215800e-01]\n",
      "\n",
      " cov :\n",
      " [[ 0.00184664  0.00529325 -0.00601384]\n",
      " [ 0.00529325  0.02519526 -0.02792123]\n",
      " [-0.00601384 -0.02792123  0.0331182 ]]\n",
      "\n",
      " prec :\n",
      " [[1380.20106989 -186.01874711   93.79832935]\n",
      " [-186.01874711  629.12383998  496.62195539]\n",
      " [  93.79832935  496.62195539  465.9185559 ]]\n",
      "\n",
      " detcov :\n",
      " 3.9723671816650785e-08\n",
      "\n",
      " n :\n",
      " 26401\n",
      "\n",
      " prior :\n",
      " 0.15799804903738546\n",
      "\n",
      "Phoneonbottom :\n",
      "\n",
      " mu :\n",
      " [0.19076794 9.78584734 0.1465572 ]\n",
      "\n",
      " cov :\n",
      " [[ 0.00273883 -0.0044379   0.00151984]\n",
      " [-0.0044379   0.01026786 -0.00328148]\n",
      " [ 0.00151984 -0.00328148  0.00247968]]\n",
      "\n",
      " prec :\n",
      " [[1229.24902343  503.42022589  -87.22678994]\n",
      " [ 503.42022589  374.93550309  187.61601574]\n",
      " [ -87.22678994  187.61601574  705.02302834]]\n",
      "\n",
      " detcov :\n",
      " 1.1952712798255282e-08\n",
      "\n",
      " n :\n",
      " 27842\n",
      "\n",
      " prior :\n",
      " 0.1666217825574367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pgc1 = mypgc()\n",
    "pgc1.fit(x_train, y_train)\n",
    "\n",
    "# calculate and show model parameters\n",
    "def mu(typ):\n",
    "    mu = np.mean(x_train[y_train == typ], axis = 0)\n",
    "    return mu\n",
    "\n",
    "def cov(typ):\n",
    "    return np.cov(x_train[y_train == typ].T)\n",
    "\n",
    "def prec(cov):\n",
    "    return np.linalg.inv(cov)\n",
    "\n",
    "def detcov(cov):\n",
    "    return np.linalg.det(cov)\n",
    "\n",
    "typp = [\"Phoneonback\", \"Phoneonfront\", \"Phoneonleft\", \"Phoneonright\", \"Phoneontop\", \"Phoneonbottom\"]\n",
    "\n",
    "model = {}\n",
    "for i in typp:\n",
    "     model[i] = {\"mu\" : mu(i), \"cov\" : cov(i), \"prec\" : prec(cov(i)), \"detcov\" : detcov(cov(i)), \"n\" : np.sum(y_train == i) , \"prior\" : np.sum(y_train == i) / len(y_train)}\n",
    "        \n",
    "for key, value in model.items():\n",
    "    print(key, \":\")\n",
    "    for key2, value2 in value.items():\n",
    "        print(\"\\n\", key2, \":\\n\", value2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-3 predict test data and show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 20 predictions and actual positions pair :\n",
      "|  prediction        |  actual              |\n",
      "[['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneontop' 'Phoneontop']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonfront' 'Phoneonfront']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonleft' 'Phoneonleft']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonbottom' 'Phoneonbottom']\n",
      " ['Phoneonback' 'Phoneonback']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneonright' 'Phoneonright']\n",
      " ['Phoneontop' 'Phoneontop']\n",
      " ['Phoneonleft' 'Phoneonleft']]\n",
      "\n",
      "numbers of correct predictions : 83511\n",
      "\n",
      "accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "ypred = pgc1.predict(x_test)\n",
    "\n",
    "res = np.array(list(it.zip_longest(ypred[:20], np.array(testdata['label'][:20]))))\n",
    "\n",
    "print(\"first 20 predictions and actual positions pair :\")\n",
    "print(\"|  prediction        |  actual              |\")\n",
    "print(res)\n",
    "\n",
    "correct = [ypred[i] == testdata['label'][i] for i in range(len(ypred))]\n",
    "accuracy = float(sum(correct)) / len(ypred)\n",
    "print()\n",
    "print(\"numbers of correct predictions :\", sum(correct))\n",
    "print()\n",
    "print(\"accuracy :\", \"{:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"adult.data.txt\", 'r')\n",
    "n = np.array(data.read().splitlines())\n",
    "\n",
    "test = open(\"adult.test.txt\", 'r')\n",
    "t = np.array(test.read().splitlines())\n",
    "\n",
    "dummy = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "conti = [0, 2, 4, 10, 11, 12]\n",
    "\n",
    "dfx = [[j.strip() for j in i.split(',')] for i in n]\n",
    "dfx = pd.DataFrame(dfx)\n",
    "\n",
    "for i in dfx.columns:\n",
    "    idx = dfx[dfx[i] == '?'].index\n",
    "    dfx.drop(idx, inplace = True)\n",
    "dfx = dfx.reset_index(drop = True)\n",
    "\n",
    "for i in dummy:\n",
    "    num = dfx[i].value_counts()\n",
    "    mask = dfx[i].isin(num[num > 10].index)\n",
    "    dfx = dfx[mask]\n",
    "    dfx.reset_index(drop = True)\n",
    "\n",
    "y_train = np.array(dfx[14])\n",
    "dfx = dfx.drop(columns = [14])\n",
    "y_train[y_train == \"<=50K\"] = 0\n",
    "y_train[y_train == \">50K\"] = 1\n",
    "y_train = y_train.astype('float')\n",
    "\n",
    "categories = {}\n",
    "for i in dummy:\n",
    "    dfx[i] = dfx[i].astype('category')\n",
    "    categories[i] = dfx[i].cat.categories\n",
    "\n",
    "x_train = pd.get_dummies(dfx, columns = dummy)\n",
    "x_train = np.array(x_train).astype('float')\n",
    "dfxt = [[j.strip() for j in i.split(',')] for i in t]\n",
    "dfxt = pd.DataFrame(dfxt)\n",
    "\n",
    "\n",
    "for i in dfxt.columns:\n",
    "    idx = dfxt[dfxt[i] == '?'].index\n",
    "    dfxt.drop(idx, inplace = True)\n",
    "dfxt = dfxt.reset_index(drop = True)\n",
    "\n",
    "y_test = np.array(dfxt[14])\n",
    "dfxt = dfxt.drop(columns = [14])\n",
    "y_test[y_test == \"<=50K.\"] = 0\n",
    "y_test[y_test == \">50K.\"] = 1\n",
    "y_test = y_test.astype('float')\n",
    "\n",
    "for i in dummy:\n",
    "    dfxt[i] = dfxt[i].astype('category')\n",
    "    dfxt[i].cat.set_categories(categories[i], inplace = True)\n",
    "\n",
    "x_test = pd.get_dummies(dfxt, columns = dummy)\n",
    "x_test = np.array(x_test).astype('float')\n",
    "\n",
    "mean = np.mean(x_train[:, :6], axis = 0)\n",
    "std = np.std(x_train[:, :6], axis = 0)\n",
    "x_train[:, :6] = (x_train[:, :6] - mean) / std\n",
    "x_test[:, :6] = (x_test[:, :6] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary statistics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train : (30152, 102)\n",
      "shape of x_test :  (15060, 102)\n",
      "shape of y_train : (30152,)\n",
      "shape of y_test : (15060,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x_train :\", x_train.shape)\n",
    "print(\"shape of x_test : \", x_test.shape)\n",
    "print(\"shape of y_train :\", y_train.shape)\n",
    "print(\"shape of y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>3.015200e+04</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "      <td>30152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.187694e-16</td>\n",
       "      <td>-2.710016e-17</td>\n",
       "      <td>-2.801921e-16</td>\n",
       "      <td>-2.226927e-17</td>\n",
       "      <td>-6.244820e-17</td>\n",
       "      <td>1.861663e-16</td>\n",
       "      <td>0.030976</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.739089</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.911880</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>0.173257</td>\n",
       "      <td>0.252696</td>\n",
       "      <td>0.439139</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.060017</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.024426</td>\n",
       "      <td>0.283474</td>\n",
       "      <td>0.046023</td>\n",
       "      <td>0.023030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632305e+00</td>\n",
       "      <td>-1.666013e+00</td>\n",
       "      <td>-3.576761e+00</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-3.333285e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.948575e-01</td>\n",
       "      <td>-6.830421e-01</td>\n",
       "      <td>-4.397050e-01</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-7.774463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.096728e-01</td>\n",
       "      <td>-1.075818e-01</td>\n",
       "      <td>-4.757293e-02</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>-7.774463e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.516436e-01</td>\n",
       "      <td>4.527373e-01</td>\n",
       "      <td>1.128823e+00</td>\n",
       "      <td>-1.474696e-01</td>\n",
       "      <td>-2.184590e-01</td>\n",
       "      <td>3.396324e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.925304e+00</td>\n",
       "      <td>1.225606e+01</td>\n",
       "      <td>2.305219e+00</td>\n",
       "      <td>1.335236e+01</td>\n",
       "      <td>1.056266e+01</td>\n",
       "      <td>4.847304e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  3.015200e+04  3.015200e+04  3.015200e+04  3.015200e+04  3.015200e+04   \n",
       "mean  -1.187694e-16 -2.710016e-17 -2.801921e-16 -2.226927e-17 -6.244820e-17   \n",
       "std    1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00   \n",
       "min   -1.632305e+00 -1.666013e+00 -3.576761e+00 -1.474696e-01 -2.184590e-01   \n",
       "25%   -7.948575e-01 -6.830421e-01 -4.397050e-01 -1.474696e-01 -2.184590e-01   \n",
       "50%   -1.096728e-01 -1.075818e-01 -4.757293e-02 -1.474696e-01 -2.184590e-01   \n",
       "75%    6.516436e-01  4.527373e-01  1.128823e+00 -1.474696e-01 -2.184590e-01   \n",
       "max    3.925304e+00  1.225606e+01  2.305219e+00  1.335236e+01  1.056266e+01   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  3.015200e+04  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean   1.861663e-16      0.030976      0.068553      0.739089      0.035620   \n",
       "std    1.000017e+00      0.173257      0.252696      0.439139      0.185343   \n",
       "min   -3.333285e+00      0.000000      0.000000      0.000000      0.000000   \n",
       "25%   -7.774463e-02      0.000000      0.000000      0.000000      0.000000   \n",
       "50%   -7.774463e-02      0.000000      0.000000      1.000000      0.000000   \n",
       "75%    3.396324e-01      0.000000      0.000000      1.000000      0.000000   \n",
       "max    4.847304e+00      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           92            93            94            95   \\\n",
       "count  ...  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean   ...      0.001128      0.003615      0.000365      0.002355   \n",
       "std    ...      0.033562      0.060017      0.019097      0.048469   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                96            97            98            99            100  \\\n",
       "count  30152.000000  30152.000000  30152.000000  30152.000000  30152.000000   \n",
       "mean       0.001393      0.000564      0.000597      0.911880      0.002123   \n",
       "std        0.037297      0.023738      0.024426      0.283474      0.046023   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                101  \n",
       "count  30152.000000  \n",
       "mean       0.000531  \n",
       "std        0.023030  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x_train)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.024953</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.068592</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.018693</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>1.003359</td>\n",
       "      <td>1.039927</td>\n",
       "      <td>1.005553</td>\n",
       "      <td>1.006950</td>\n",
       "      <td>0.172628</td>\n",
       "      <td>0.252768</td>\n",
       "      <td>0.443034</td>\n",
       "      <td>0.191158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.044589</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.278089</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.632305</td>\n",
       "      <td>-1.668635</td>\n",
       "      <td>-3.576761</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-3.333285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.794857</td>\n",
       "      <td>-0.692221</td>\n",
       "      <td>-0.439705</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-0.077745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.109673</td>\n",
       "      <td>-0.112030</td>\n",
       "      <td>-0.047573</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>-0.077745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.727775</td>\n",
       "      <td>0.461854</td>\n",
       "      <td>1.128823</td>\n",
       "      <td>-0.147470</td>\n",
       "      <td>-0.218459</td>\n",
       "      <td>0.339632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.925304</td>\n",
       "      <td>12.309959</td>\n",
       "      <td>2.305219</td>\n",
       "      <td>13.352363</td>\n",
       "      <td>9.112309</td>\n",
       "      <td>4.847304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.024953     -0.001658     -0.003360      0.003771      0.001920   \n",
       "std        1.018693      0.999622      1.003359      1.039927      1.005553   \n",
       "min       -1.632305     -1.668635     -3.576761     -0.147470     -0.218459   \n",
       "25%       -0.794857     -0.692221     -0.439705     -0.147470     -0.218459   \n",
       "50%       -0.109673     -0.112030     -0.047573     -0.147470     -0.218459   \n",
       "75%        0.727775      0.461854      1.128823     -0.147470     -0.218459   \n",
       "max        3.925304     12.309959      2.305219     13.352363      9.112309   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.001690      0.030744      0.068592      0.731806      0.037981   \n",
       "std        1.006950      0.172628      0.252768      0.443034      0.191158   \n",
       "min       -3.333285      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       -0.077745      0.000000      0.000000      0.000000      0.000000   \n",
       "50%       -0.077745      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.339632      0.000000      0.000000      1.000000      0.000000   \n",
       "max        4.847304      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           92            93            94            95   \\\n",
       "count  ...  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean   ...      0.001859      0.004382      0.000598      0.001992   \n",
       "std    ...      0.043080      0.066057      0.024440      0.044589   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                96            97            98            99            100  \\\n",
       "count  15060.000000  15060.000000  15060.000000  15060.000000  15060.000000   \n",
       "mean       0.000863      0.000797      0.000531      0.915538      0.001262   \n",
       "std        0.029369      0.028218      0.023043      0.278089      0.035498   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                101  \n",
       "count  15060.000000  \n",
       "mean       0.000465  \n",
       "std        0.021555  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(x_test)\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2:\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept    \n",
    "        \n",
    "    def fit(self, x_train, y_train, verbose = False):\n",
    "        \n",
    "        if self.add_intercept:\n",
    "            self.x_train = np.c_[x_train, np.ones(x_train.shape[0])]\n",
    "        else:\n",
    "            self.x_train = x_train\n",
    "        \n",
    "        self.y_train = y_train\n",
    "        \n",
    "        w = np.linalg.inv(np.dot(self.x_train.T, self.x_train) + np.mean(self.reg_vec) * np.identity(self.reg_vec.shape[0]))\n",
    "        w = np.dot(w, self.x_train.T)\n",
    "        w = np.dot(w, self.y_train)\n",
    "        self.w = w\n",
    "        e = self.reg_error(self.x_train, self.y_train, self.w, self.reg_vec)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            z = np.dot(self.x_train, self.w)\n",
    "            pred = self.sigmoid(z)\n",
    "            error = pred - self.y_train\n",
    "            grad = (self.reg_vec * self.w) + np.dot(self.x_train.T, error)\n",
    "            R = pred * (1 - pred)\n",
    "            hess = self.x_train.T * R\n",
    "            hess = np.dot(hess, self.x_train) + np.identity(self.reg_vec.shape[0]) * self.reg_vec\n",
    "            if i == 0 and verbose:\n",
    "                print(\"gradient :\", grad)\n",
    "                print(\"hessian :\", hess)\n",
    "            self.w = self.w - np.dot(np.linalg.pinv(hess), grad)\n",
    "            \n",
    "            next_error = self.reg_error(self.x_train, self.y_train, self.w, self.reg_vec)\n",
    "            if abs(e - next_error) < self.tol:\n",
    "                break\n",
    "            e = next_error\n",
    "            \n",
    "    def predict(self, x_test):\n",
    "        if self.add_intercept:\n",
    "            x_test = np.c_[x_test, np.ones(x_test.shape[0])]\n",
    "        z = np.dot(x_test, self.w)\n",
    "        res = np.array([self.sigmoid(i) for i in z])\n",
    "        res[res >= 0.5] = 1\n",
    "        res[res < 0.5] = 0\n",
    "        return res\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def reg_error(self, x_train, y_train, w, reg_vec):\n",
    "        z = np.dot(x_train, w) \n",
    "        reg_term = (1/2) * np.dot(reg_vec * w.T, w)\n",
    "        return -1 * np.sum((y_train * np.log(self.sigmoid(z) + 1e-5)) + ((1 - y_train) * np.log(1 - self.sigmoid(z) + 1e-5))) + reg_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-2 Derive the gradient and hession matrix for the new E(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dfc91782bc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogic1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmylogistic_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e7d14ee7f182>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "lambda_vec = np.array([1] * (x_train.shape[1] + 1))\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.2%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.array([1] * (x_train.shape[1]) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.2%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-3 Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.array([1] * 6 + [0.5] * (x_train.shape[1] - 6) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = logic1.predict(x_test)\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.2%}\".format(sum(p == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_tune, y_train_s, y_tune = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "max_acc = 0\n",
    "alpha = 0\n",
    "grids = np.logspace(-2, 2, 10)\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([i] * (x_train.shape[1]) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        alpha = i\n",
    "print(\"a1*, a2* :\", alpha)\n",
    "print(\"accuracy :\", \"{:.2%}\".format(max_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search new a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2 = 0\n",
    "max_acc2 = 0\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([alpha] * 6 + [i] * (x_train.shape[1] - 6) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc2:\n",
    "        max_acc2 = acc\n",
    "        alpha2 = i\n",
    "print(\"a2* :\", alpha2)\n",
    "print(\"accuracy :\", \"{:.2%}\".format(max_acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 search new a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = 0\n",
    "max_acc1 = 0\n",
    "for i in grids:\n",
    "    lambda_vec = np.array([i] * 6 + [alpha2] * (x_train.shape[1] - 6) + [0])\n",
    "    logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic1.fit(x_train_s, y_train_s, False)\n",
    "    p = logic1.predict(x_tune)\n",
    "    acc = sum(p == y_tune) / len(y_tune)\n",
    "    if acc >= max_acc1:\n",
    "        max_acc1 = acc\n",
    "        alpha1 = i\n",
    "print(\"a1* :\", alpha1)\n",
    "print(\"accuracy :\", \"{:.2%}\".format(max_acc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 report a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best a1 :\", alpha1)\n",
    "print(\"best a2 :\", alpha2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-4 train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = np.array([alpha1] * 6 + [alpha2] * (x_train.shape[1] - 6) + [0])\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train, False)\n",
    "p = logic1.predict(x_test)\n",
    "acc = sum(p == y_test) / len(y_test)\n",
    "print(\"accuracy :\", \"{:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "max_acc = 0\n",
    "best_c = 0\n",
    "for c in grids:\n",
    "    logic2 = LogisticRegression(solver = 'lbfgs', max_iter = 1000, tol = 1e-5, n_jobs = -1, C = c)\n",
    "    logic2.fit(x_train_s, y_train_s)\n",
    "    p = logic2.predict(x_tune)\n",
    "    accc = sum(p == y_tune) / len(y_tune)\n",
    "    if accc > max_acc:\n",
    "        max_acc = accc\n",
    "        best_c = c\n",
    "        \n",
    "logic2 = LogisticRegression(solver = 'lbfgs', max_iter = 1000, tol = 1e-5, n_jobs = -1, C = best_c)\n",
    "logic2.fit(x_train, y_train)\n",
    "p = logic2.predict(x_test)\n",
    "acc2 = sum(p == y_test) / len(y_test)\n",
    "\n",
    "print(\"====== scikit learn logistic regression model result ======\")\n",
    "print(\"w :\")\n",
    "print(logic2.coef_)\n",
    "print(\"\\naccuracy :\", \"{:.2%}\".format(acc2))\n",
    "\n",
    "print(\"\\n====== my own logistic regression model result ======\")\n",
    "print(\"w :\")\n",
    "print(logic1.w)\n",
    "print(\"\\naccuracy :\", \"{:.2%}\".format(acc))\n",
    "\n",
    "print(\"\\naccuracy difference between two models :\", abs(acc - acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When random state is set to 42, two models have same prediction ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
